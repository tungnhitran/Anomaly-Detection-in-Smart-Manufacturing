{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit ('deeplearning_venv': venv)",
      "metadata": {
        "interpreter": {
          "hash": "9139ca13fc640d8623238ac4ed44beace8a76f86a07bab6efe75c2506e18783d"
        }
      }
    },
    "colab": {
      "name": "Copy of 2021-03-14-tabular-data-variational-autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tungnhitran/VAE-Anomaly-Detection-in-Predictive-Maintenance/blob/main/variational_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F48kSuoYO6Bj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        " \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saG35lgTO6Bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e70bca-f313-4bd4-9678-a3a3aec9b58b"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWd2T9BvO6Bm"
      },
      "source": [
        "TRAIN_PATH = 'dry run.csv'\n",
        "TEST_PATH = 'test_data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyQ-V5IkO6Bn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "afedd4ed-5e60-4421-dcb3-1620ce264d7b"
      },
      "source": [
        "df_base = pd.read_csv(TRAIN_PATH, sep=',')\n",
        "cols = df_base.columns\n",
        "cols\n",
        "del df_base['time']\n",
        "\n",
        "df_anomaly = pd.read_csv(TEST_PATH, sep=',')\n",
        "del df_anomaly['time']\n",
        "df_base.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ax</th>\n",
              "      <th>ay</th>\n",
              "      <th>az</th>\n",
              "      <th>aT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.3246</td>\n",
              "      <td>0.2748</td>\n",
              "      <td>0.1502</td>\n",
              "      <td>0.451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6020</td>\n",
              "      <td>-0.1900</td>\n",
              "      <td>-0.3227</td>\n",
              "      <td>0.709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9787</td>\n",
              "      <td>0.3258</td>\n",
              "      <td>0.0124</td>\n",
              "      <td>1.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6141</td>\n",
              "      <td>-0.4179</td>\n",
              "      <td>0.0471</td>\n",
              "      <td>0.744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.3218</td>\n",
              "      <td>-0.6389</td>\n",
              "      <td>-0.4259</td>\n",
              "      <td>0.833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ax      ay      az     aT\n",
              "0 -0.3246  0.2748  0.1502  0.451\n",
              "1  0.6020 -0.1900 -0.3227  0.709\n",
              "2  0.9787  0.3258  0.0124  1.032\n",
              "3  0.6141 -0.4179  0.0471  0.744\n",
              "4 -0.3218 -0.6389 -0.4259  0.833"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sxJmav1O6Bo"
      },
      "source": [
        "## Build Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os_v6B89O6Bo"
      },
      "source": [
        "def load_and_standardize_data(path):\n",
        "    # read in from csv\n",
        "    df = pd.read_csv(path, sep=',')\n",
        "    # replace nan with -99\n",
        "    df = df.fillna(-99)\n",
        "    df = df.values.reshape(-1, df.shape[1]).astype('float32')\n",
        "    # randomly split\n",
        "    X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)\n",
        "    # standardize values\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)   \n",
        "    return X_train, X_test, scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttSiv3ylO6Bp"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class DataBuilder(Dataset):\n",
        "    def __init__(self, path, train=True):\n",
        "        self.X_train, self.X_test, self.standardizer = load_and_standardize_data(TRAIN_PATH)\n",
        "        if train:\n",
        "            self.x = torch.from_numpy(self.X_train)\n",
        "            self.len=self.x.shape[0]\n",
        "        else:\n",
        "            self.x = torch.from_numpy(self.X_test)\n",
        "            self.len=self.x.shape[0]\n",
        "        del self.X_train\n",
        "        del self.X_test \n",
        "    def __getitem__(self,index):      \n",
        "        return self.x[index]\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDSlWGqcO6Bp"
      },
      "source": [
        "traindata_set=DataBuilder(TRAIN_PATH, train=True)\n",
        "testdata_set=DataBuilder(TRAIN_PATH, train=False)\n",
        "anomalydata_set=DataBuilder(TEST_PATH,train=True)\n",
        "\n",
        "trainloader=DataLoader(dataset=traindata_set,batch_size=128)\n",
        "testloader=DataLoader(dataset=testdata_set,batch_size=128)\n",
        "anomalyloader=DataLoader(anomalydata_set,batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sglQ_Wa_O6Bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def09d0b-50ab-4bd5-d6e6-8de5fd352f05"
      },
      "source": [
        "type(trainloader.dataset.x), type(testloader.dataset.x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdiiRFjWO6Bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d77550-5505-47f3-a732-4bad1c1d16f4"
      },
      "source": [
        "trainloader.dataset.x.shape, testloader.dataset.x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4622, 5]), torch.Size([1982, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ2dXovoO6Bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a5cabe-a30b-473c-bf30-675fb7a4de28"
      },
      "source": [
        "trainloader.dataset.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3910,  1.0411,  1.1225,  1.4695,  0.7925],\n",
              "        [ 0.1313,  1.1235,  0.9828,  0.5512, -0.2227],\n",
              "        [ 0.3081, -0.1503, -0.3431, -0.2122, -1.4265],\n",
              "        ...,\n",
              "        [ 0.9999,  0.7574, -0.1963, -0.0993, -1.2231],\n",
              "        [ 1.0849,  0.2104, -0.7661, -0.3276, -0.8934],\n",
              "        [-1.2956,  0.8494,  0.8129,  1.1837,  0.1546]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7yfnCoAO6Br"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,D_in,H,H2,latent_dim=2):\n",
        "        \n",
        "        #Encoder\n",
        "        super(Autoencoder,self).__init__()\n",
        "        self.linear1=nn.Linear(D_in,H)\n",
        "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
        "        self.linear2=nn.Linear(H,H2)\n",
        "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
        "        self.linear3=nn.Linear(H2,H2)\n",
        "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
        "        \n",
        "        # Latent vectors mu and sigma\n",
        "        self.fc1 = nn.Linear(H2, latent_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
        "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
        "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "        # Sampling vector\n",
        "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
        "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
        "        self.fc4 = nn.Linear(latent_dim, H2)\n",
        "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
        "        \n",
        "        # Decoder\n",
        "        self.linear4=nn.Linear(H2,H2)\n",
        "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
        "        self.linear5=nn.Linear(H2,H)\n",
        "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
        "        self.linear6=nn.Linear(H,D_in)\n",
        "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def encode(self, x):\n",
        "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
        "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
        "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
        "\n",
        "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
        "\n",
        "        r1 = self.fc21(fc1)\n",
        "        r2 = self.fc22(fc1)\n",
        "        \n",
        "        return r1, r2\n",
        "    \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "        \n",
        "    def decode(self, z):\n",
        "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
        "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
        "\n",
        "        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))\n",
        "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
        "        return self.lin_bn6(self.linear6(lin5))\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnypHDAzO6Bs"
      },
      "source": [
        "class customLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(customLoss, self).__init__()\n",
        "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
        "    \n",
        "    def forward(self, x_recon, x, mu, logvar):\n",
        "        loss_MSE = self.mse_loss(x_recon, x)\n",
        "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        return loss_MSE + loss_KLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1vYzJ-AO6Bs"
      },
      "source": [
        "If you want to better understand the variational autoencoder technique, look [here](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73).\n",
        "\n",
        "For better understanding this AutoencoderClass, let me go briefly through it. This is a variational autoencoder (VAE) with two hidden layers, which (by default, but you can change this) 50 and then 12 activations. The latent factors are set to 3 (you can change that, too). So we're first exploding our initially 14 variables to 50 activations, then condensing it to 12, then to 3. From these 3 latent factors we then sample to recreate the original 14 values. We do that by inflating the 3 latent factors back to 12, then 50 and finally 14 activations (we decode the latent factors so to speak). With this reconstructed batch (recon_batch) we compare it with the original batch, computate our loss and adjust the weights and biases via our gradient (our optimizer here will be Adam). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCUVSrtfO6Bt"
      },
      "source": [
        "D_in = traindata_set.x.shape[1]\n",
        "H = 50\n",
        "H2 = 12\n",
        "model = Autoencoder(D_in, H, H2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSkKW-dFO6Bt"
      },
      "source": [
        "loss_mse = customLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w46R0TqdO6Bt"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vBaWLPGO6Bt"
      },
      "source": [
        "epochs = 200\n",
        "log_interval = 50\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "test_losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL5xfvnoO6Bu"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(trainloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    if epoch % 20 == 0:        \n",
        "        print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
        "            epoch, train_loss / len(trainloader.dataset)))\n",
        "        train_losses.append(train_loss / len(trainloader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POE6G2-2O6Bu"
      },
      "source": [
        "def test(epoch):\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        for batch_idx, data in enumerate(testloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            loss = loss_mse(recon_batch, data, mu, logvar)\n",
        "            test_loss += loss.item()\n",
        "            if epoch % 20 == 0:        \n",
        "                print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
        "                    epoch, test_loss / len(testloader.dataset)))\n",
        "            test_losses.append(test_loss / len(testloader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6WduskBO6Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a04b53-90c6-4bc7-eace-4f916005b363"
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Epoch: 20 Average training loss: 4.2282\n",
            "====> Epoch: 20 Average test loss: 0.2645\n",
            "====> Epoch: 20 Average test loss: 0.5376\n",
            "====> Epoch: 20 Average test loss: 0.8357\n",
            "====> Epoch: 20 Average test loss: 1.1030\n",
            "====> Epoch: 20 Average test loss: 1.3604\n",
            "====> Epoch: 20 Average test loss: 1.6524\n",
            "====> Epoch: 20 Average test loss: 1.9190\n",
            "====> Epoch: 20 Average test loss: 2.1814\n",
            "====> Epoch: 20 Average test loss: 2.4366\n",
            "====> Epoch: 20 Average test loss: 2.7002\n",
            "====> Epoch: 20 Average test loss: 2.9550\n",
            "====> Epoch: 20 Average test loss: 3.2269\n",
            "====> Epoch: 20 Average test loss: 3.5018\n",
            "====> Epoch: 20 Average test loss: 3.7850\n",
            "====> Epoch: 20 Average test loss: 4.0663\n",
            "====> Epoch: 20 Average test loss: 4.1936\n",
            "====> Epoch: 40 Average training loss: 3.8604\n",
            "====> Epoch: 40 Average test loss: 0.2373\n",
            "====> Epoch: 40 Average test loss: 0.4840\n",
            "====> Epoch: 40 Average test loss: 0.7492\n",
            "====> Epoch: 40 Average test loss: 0.9928\n",
            "====> Epoch: 40 Average test loss: 1.2262\n",
            "====> Epoch: 40 Average test loss: 1.4898\n",
            "====> Epoch: 40 Average test loss: 1.7255\n",
            "====> Epoch: 40 Average test loss: 1.9605\n",
            "====> Epoch: 40 Average test loss: 2.1924\n",
            "====> Epoch: 40 Average test loss: 2.4376\n",
            "====> Epoch: 40 Average test loss: 2.6775\n",
            "====> Epoch: 40 Average test loss: 2.9279\n",
            "====> Epoch: 40 Average test loss: 3.1675\n",
            "====> Epoch: 40 Average test loss: 3.4204\n",
            "====> Epoch: 40 Average test loss: 3.6848\n",
            "====> Epoch: 40 Average test loss: 3.8003\n",
            "====> Epoch: 60 Average training loss: 3.7792\n",
            "====> Epoch: 60 Average test loss: 0.2351\n",
            "====> Epoch: 60 Average test loss: 0.4677\n",
            "====> Epoch: 60 Average test loss: 0.7236\n",
            "====> Epoch: 60 Average test loss: 0.9688\n",
            "====> Epoch: 60 Average test loss: 1.2048\n",
            "====> Epoch: 60 Average test loss: 1.4605\n",
            "====> Epoch: 60 Average test loss: 1.7132\n",
            "====> Epoch: 60 Average test loss: 1.9440\n",
            "====> Epoch: 60 Average test loss: 2.1776\n",
            "====> Epoch: 60 Average test loss: 2.4212\n",
            "====> Epoch: 60 Average test loss: 2.6491\n",
            "====> Epoch: 60 Average test loss: 2.9062\n",
            "====> Epoch: 60 Average test loss: 3.1496\n",
            "====> Epoch: 60 Average test loss: 3.3940\n",
            "====> Epoch: 60 Average test loss: 3.6443\n",
            "====> Epoch: 60 Average test loss: 3.7625\n",
            "====> Epoch: 80 Average training loss: 3.7674\n",
            "====> Epoch: 80 Average test loss: 0.2430\n",
            "====> Epoch: 80 Average test loss: 0.4764\n",
            "====> Epoch: 80 Average test loss: 0.7242\n",
            "====> Epoch: 80 Average test loss: 0.9651\n",
            "====> Epoch: 80 Average test loss: 1.2111\n",
            "====> Epoch: 80 Average test loss: 1.4636\n",
            "====> Epoch: 80 Average test loss: 1.7121\n",
            "====> Epoch: 80 Average test loss: 1.9438\n",
            "====> Epoch: 80 Average test loss: 2.1744\n",
            "====> Epoch: 80 Average test loss: 2.4139\n",
            "====> Epoch: 80 Average test loss: 2.6583\n",
            "====> Epoch: 80 Average test loss: 2.9018\n",
            "====> Epoch: 80 Average test loss: 3.1443\n",
            "====> Epoch: 80 Average test loss: 3.4031\n",
            "====> Epoch: 80 Average test loss: 3.6514\n",
            "====> Epoch: 80 Average test loss: 3.7649\n",
            "====> Epoch: 100 Average training loss: 3.7184\n",
            "====> Epoch: 100 Average test loss: 0.2409\n",
            "====> Epoch: 100 Average test loss: 0.4791\n",
            "====> Epoch: 100 Average test loss: 0.7361\n",
            "====> Epoch: 100 Average test loss: 0.9759\n",
            "====> Epoch: 100 Average test loss: 1.2180\n",
            "====> Epoch: 100 Average test loss: 1.4636\n",
            "====> Epoch: 100 Average test loss: 1.7065\n",
            "====> Epoch: 100 Average test loss: 1.9240\n",
            "====> Epoch: 100 Average test loss: 2.1564\n",
            "====> Epoch: 100 Average test loss: 2.3967\n",
            "====> Epoch: 100 Average test loss: 2.6313\n",
            "====> Epoch: 100 Average test loss: 2.8717\n",
            "====> Epoch: 100 Average test loss: 3.1143\n",
            "====> Epoch: 100 Average test loss: 3.3619\n",
            "====> Epoch: 100 Average test loss: 3.6142\n",
            "====> Epoch: 100 Average test loss: 3.7249\n",
            "====> Epoch: 120 Average training loss: 3.7159\n",
            "====> Epoch: 120 Average test loss: 0.2377\n",
            "====> Epoch: 120 Average test loss: 0.4848\n",
            "====> Epoch: 120 Average test loss: 0.7439\n",
            "====> Epoch: 120 Average test loss: 0.9932\n",
            "====> Epoch: 120 Average test loss: 1.2334\n",
            "====> Epoch: 120 Average test loss: 1.4896\n",
            "====> Epoch: 120 Average test loss: 1.7316\n",
            "====> Epoch: 120 Average test loss: 1.9498\n",
            "====> Epoch: 120 Average test loss: 2.1766\n",
            "====> Epoch: 120 Average test loss: 2.4093\n",
            "====> Epoch: 120 Average test loss: 2.6415\n",
            "====> Epoch: 120 Average test loss: 2.8914\n",
            "====> Epoch: 120 Average test loss: 3.1304\n",
            "====> Epoch: 120 Average test loss: 3.3851\n",
            "====> Epoch: 120 Average test loss: 3.6391\n",
            "====> Epoch: 120 Average test loss: 3.7550\n",
            "====> Epoch: 140 Average training loss: 3.7079\n",
            "====> Epoch: 140 Average test loss: 0.2350\n",
            "====> Epoch: 140 Average test loss: 0.4755\n",
            "====> Epoch: 140 Average test loss: 0.7261\n",
            "====> Epoch: 140 Average test loss: 0.9653\n",
            "====> Epoch: 140 Average test loss: 1.2071\n",
            "====> Epoch: 140 Average test loss: 1.4546\n",
            "====> Epoch: 140 Average test loss: 1.6963\n",
            "====> Epoch: 140 Average test loss: 1.9207\n",
            "====> Epoch: 140 Average test loss: 2.1525\n",
            "====> Epoch: 140 Average test loss: 2.3847\n",
            "====> Epoch: 140 Average test loss: 2.6174\n",
            "====> Epoch: 140 Average test loss: 2.8604\n",
            "====> Epoch: 140 Average test loss: 3.1004\n",
            "====> Epoch: 140 Average test loss: 3.3484\n",
            "====> Epoch: 140 Average test loss: 3.5940\n",
            "====> Epoch: 140 Average test loss: 3.7106\n",
            "====> Epoch: 160 Average training loss: 3.7060\n",
            "====> Epoch: 160 Average test loss: 0.2284\n",
            "====> Epoch: 160 Average test loss: 0.4637\n",
            "====> Epoch: 160 Average test loss: 0.7096\n",
            "====> Epoch: 160 Average test loss: 0.9491\n",
            "====> Epoch: 160 Average test loss: 1.1976\n",
            "====> Epoch: 160 Average test loss: 1.4493\n",
            "====> Epoch: 160 Average test loss: 1.6952\n",
            "====> Epoch: 160 Average test loss: 1.9136\n",
            "====> Epoch: 160 Average test loss: 2.1354\n",
            "====> Epoch: 160 Average test loss: 2.3771\n",
            "====> Epoch: 160 Average test loss: 2.6094\n",
            "====> Epoch: 160 Average test loss: 2.8547\n",
            "====> Epoch: 160 Average test loss: 3.0940\n",
            "====> Epoch: 160 Average test loss: 3.3452\n",
            "====> Epoch: 160 Average test loss: 3.5904\n",
            "====> Epoch: 160 Average test loss: 3.7089\n",
            "====> Epoch: 180 Average training loss: 3.7263\n",
            "====> Epoch: 180 Average test loss: 0.2337\n",
            "====> Epoch: 180 Average test loss: 0.4686\n",
            "====> Epoch: 180 Average test loss: 0.7301\n",
            "====> Epoch: 180 Average test loss: 0.9805\n",
            "====> Epoch: 180 Average test loss: 1.2240\n",
            "====> Epoch: 180 Average test loss: 1.4656\n",
            "====> Epoch: 180 Average test loss: 1.7135\n",
            "====> Epoch: 180 Average test loss: 1.9441\n",
            "====> Epoch: 180 Average test loss: 2.1695\n",
            "====> Epoch: 180 Average test loss: 2.4076\n",
            "====> Epoch: 180 Average test loss: 2.6459\n",
            "====> Epoch: 180 Average test loss: 2.8935\n",
            "====> Epoch: 180 Average test loss: 3.1285\n",
            "====> Epoch: 180 Average test loss: 3.3850\n",
            "====> Epoch: 180 Average test loss: 3.6349\n",
            "====> Epoch: 180 Average test loss: 3.7466\n",
            "====> Epoch: 200 Average training loss: 3.6951\n",
            "====> Epoch: 200 Average test loss: 0.2438\n",
            "====> Epoch: 200 Average test loss: 0.4865\n",
            "====> Epoch: 200 Average test loss: 0.7393\n",
            "====> Epoch: 200 Average test loss: 0.9830\n",
            "====> Epoch: 200 Average test loss: 1.2226\n",
            "====> Epoch: 200 Average test loss: 1.4701\n",
            "====> Epoch: 200 Average test loss: 1.7130\n",
            "====> Epoch: 200 Average test loss: 1.9343\n",
            "====> Epoch: 200 Average test loss: 2.1641\n",
            "====> Epoch: 200 Average test loss: 2.4077\n",
            "====> Epoch: 200 Average test loss: 2.6431\n",
            "====> Epoch: 200 Average test loss: 2.8880\n",
            "====> Epoch: 200 Average test loss: 3.1241\n",
            "====> Epoch: 200 Average test loss: 3.3773\n",
            "====> Epoch: 200 Average test loss: 3.6201\n",
            "====> Epoch: 200 Average test loss: 3.7331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58f4B39mO6Bv"
      },
      "source": [
        "with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(testloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPCsce9CO6Bv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2ec7fe-c55f-41c3-facc-2f86f299b285"
      },
      "source": [
        "scaler = trainloader.dataset.standardizer\n",
        "recon_row = scaler.inverse_transform(recon_batch[0].cpu().numpy())\n",
        "real_row = scaler.inverse_transform(testloader.dataset.x[0].cpu().numpy())\n",
        "print(real_row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14.843   0.4923  1.033   0.1377  1.153 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY9x7r00O6Bv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "4253dd64-b02e-41c4-f344-0df204ab5ab8"
      },
      "source": [
        "df = pd.DataFrame(np.stack((recon_row, real_row)), columns = cols)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>ax</th>\n",
              "      <th>ay</th>\n",
              "      <th>az</th>\n",
              "      <th>aT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.998652</td>\n",
              "      <td>0.087614</td>\n",
              "      <td>0.029141</td>\n",
              "      <td>-0.067593</td>\n",
              "      <td>0.788637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.843000</td>\n",
              "      <td>0.492300</td>\n",
              "      <td>1.033000</td>\n",
              "      <td>0.137700</td>\n",
              "      <td>1.153000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        time        ax        ay        az        aT\n",
              "0  29.998652  0.087614  0.029141 -0.067593  0.788637\n",
              "1  14.843000  0.492300  1.033000  0.137700  1.153000"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9eL7qanO6Bw"
      },
      "source": [
        "sigma = torch.exp(logvar/2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Fso1xrO6Bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f76cbb-506c-4d37-db8d-64499c6227f0"
      },
      "source": [
        "mu[1], sigma[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0077, -1.2706], device='cuda:0'),\n",
              " tensor([0.9993, 0.3363], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acOgFMyjO6Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf158101-d482-4f29-c0ba-4845585e9d9b"
      },
      "source": [
        "mu.mean(axis=0), sigma.mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0007, 0.0092], device='cuda:0'),\n",
              " tensor([0.9990, 0.3566], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Oqb15zO6Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d68af9-ac95-4f95-e3b4-fe9506f4e4db"
      },
      "source": [
        "# sample z from q\n",
        "no_samples = traindata_set.x.shape[0]\n",
        "q = torch.distributions.Normal(mu.mean(axis=0), sigma.mean(axis=0))\n",
        "z = q.rsample(sample_shape=torch.Size([no_samples]))\n",
        "print(no_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avNM6aXlO6By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8499b05-6aec-4078-8921-0d1eb1428b34"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4622, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp0v60HLO6By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af223b5c-de5e-45fc-a3a9-0b56a8f90282"
      },
      "source": [
        "z[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.6702,  0.1200],\n",
              "        [-0.4516,  0.1900],\n",
              "        [ 0.4871,  0.0086],\n",
              "        [-2.1263,  0.2678],\n",
              "        [-0.3308, -0.3156]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oAeKed2O6Bz"
      },
      "source": [
        "with torch.no_grad():\n",
        "    pred = model.decode(z).cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsohZZqdO6B0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce417d6f-4bb7-4716-bf5c-0c17b6f277a3"
      },
      "source": [
        "pred[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.09934235,  0.5321117 ,  0.64761573,  0.20795664, -0.34611413],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6pa3DLpO6B1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0d803a-93f1-49de-d413-5df1658fa91d"
      },
      "source": [
        "fake_data = scaler.inverse_transform(pred)\n",
        "fake_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4622, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lpQNtWyO6B1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d206d5d-7f08-40c8-9657-eb6ec682d179"
      },
      "source": [
        "df_fake = pd.DataFrame(fake_data, columns = cols)\n",
        "df_fake['time'] = np.round(df_fake['time']).astype(int)\n",
        "#df_fake['time'] = np.where(df_fake['time']<1, 1, df_fake['time'])\n",
        "print(df_fake)\n",
        "df_fake.to_csv('fake.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      time        ax        ay        az        aT\n",
            "0       31  0.197441  0.238622  0.014365  0.912715\n",
            "1       31  0.338270  0.523044  0.106282  1.071723\n",
            "2       30  0.061207 -0.015579 -0.079240  0.823674\n",
            "3       33  0.436639  0.688422  0.207337  1.202315\n",
            "4       35 -0.465837 -0.615207 -0.673676  1.263743\n",
            "...    ...       ...       ...       ...       ...\n",
            "4617    36  0.582693  0.883618  0.473752  1.490480\n",
            "4618    31  0.024764 -0.040416 -0.146738  0.834721\n",
            "4619    36  0.583659  0.548244  1.390502  1.977449\n",
            "4620    31 -0.013189 -0.134117 -0.139786  0.834939\n",
            "4621    31  0.107516  0.094563 -0.074430  0.865624\n",
            "\n",
            "[4622 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wItt0TZlO6B2"
      },
      "source": [
        "For comparison the real data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUlLZZGGJuCN",
        "outputId": "ebc5bc62-cfe3-4012-a136-9096af0808cf"
      },
      "source": [
        "#generate from anomaly data\n",
        "with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(anomalyloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "\n",
        "scaler = anomalyloader.dataset.standardizer\n",
        "recon_test_row = scaler.inverse_transform(recon_batch[0].cpu().numpy())\n",
        "sigma = torch.exp(logvar/2)\n",
        "\n",
        "no_samples_test = df_anomaly.shape[0]\n",
        "q = torch.distributions.Normal(mu.mean(axis=0), sigma.mean(axis=0))\n",
        "z = q.rsample(sample_shape=torch.Size([no_samples_test]))\n",
        "print(no_samples_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp6zpdIr8VDW",
        "outputId": "a4cb85d7-178e-4596-bf13-78be195e8400"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([29224, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXYWuCqmhbTs",
        "outputId": "49ba852b-e41b-45d7-d865-b34ff612b762"
      },
      "source": [
        "with torch.no_grad():\n",
        "    pred_test = model.decode(z).cpu().numpy()\n",
        "fake_data_test = scaler.inverse_transform(pred_test)\n",
        "\n",
        "df_fake_test = pd.DataFrame(fake_data_test, columns = cols)\n",
        "df_fake_test['time'] = np.round(df_fake_test['time']).astype(int)\n",
        "#df_fake_test['time'] = np.where(df_fake_test['time']<1, 1, df_fake_test['time'])\n",
        "del df_fake_test['time']\n",
        "print(df_fake_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             ax        ay        az        aT\n",
            "0      0.575444  0.110038  3.175564  3.346946\n",
            "1      0.391271  0.609004  0.151937  1.133889\n",
            "2     -0.212289 -0.406150 -0.342882  0.961295\n",
            "3     -0.092752 -0.197173 -0.293937  0.935848\n",
            "4     -0.011454 -0.103941 -0.182523  0.840272\n",
            "...         ...       ...       ...       ...\n",
            "29219 -0.251613 -0.448805 -0.388939  0.986673\n",
            "29220 -0.836800 -0.855298 -1.209944  1.848542\n",
            "29221  0.017254 -0.063133 -0.146929  0.834483\n",
            "29222  0.114969  0.104149 -0.072868  0.871952\n",
            "29223  0.546512  0.185186  2.584267  2.840847\n",
            "\n",
            "[29224 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofv7FjxZh6Cg",
        "outputId": "ba2910b8-a6d4-4a7f-c63b-086799c93d0a"
      },
      "source": [
        "#reconstruction error test data\n",
        "#del df_fake_test['time']\n",
        "mse_test = ((df_anomaly-df_fake_test)**2).max(axis=1)\n",
        "print(mse_test)\n",
        "mse_test.to_csv('mse_test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        11.727641\n",
            "1         1.321036\n",
            "2         0.474559\n",
            "3         0.347660\n",
            "4         0.370085\n",
            "           ...    \n",
            "29219     1.344641\n",
            "29220    16.899041\n",
            "29221     2.616361\n",
            "29222     2.532717\n",
            "29223    20.238901\n",
            "Length: 29224, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnrpvYFFiR-h",
        "outputId": "b3ff8f04-2d55-4029-b7f2-64221bd04635"
      },
      "source": [
        "#reconstruction error train data\n",
        "#del df_base['time']\n",
        "#del df_fake['time']\n",
        "mse = ((df_base[0:4622]-df_fake)**2).mean(axis=1)\n",
        "print(mse)\n",
        "mse.to_csv('mse.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       0.126367\n",
            "1       0.223395\n",
            "2       0.252533\n",
            "3       0.372792\n",
            "4       0.067060\n",
            "          ...   \n",
            "4617    1.055836\n",
            "4618    0.854574\n",
            "4619    1.464029\n",
            "4620    3.105731\n",
            "4621    0.214447\n",
            "Length: 4622, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93_uSPIfmjjL",
        "outputId": "7443d266-e011-426e-b927-536c779f8ec0"
      },
      "source": [
        "#threshold = np.quantile(mse,0.9)\n",
        "threshold = mse.mean()\n",
        "print(threshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.916231494643133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "aGDyT6N35Gh5",
        "outputId": "b5829d31-2a4c-4de0-ceeb-20d26601f7b2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(8, 6), dpi=80)\n",
        "plt.plot(mse[0:100],'go',label='healthy')\n",
        "plt.plot(mse_test[0:100],'rs',label='anomaly')\n",
        "plt.axhline(y=threshold,color='r', linestyle='-',label='threshold')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Observations\")\n",
        "plt.ylabel(\"Anomaly Score\")\n",
        "plt.title('Anomaly Detection Results')\n",
        "plt.savefig('AD.pdf')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}